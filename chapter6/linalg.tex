	\section{Lineare Algebra}
		\subsection{cuBLAS und clBLAS}
		Um für Programmierer das Implementieren von Algorithmen in der linearen Algebra zu erleichtern, wurden in den 70er Jahren in Fortran verschiedenen Matrix- und Vektoroperationen hardwarenah implementiert. Diese Bibliothek ist als \textit{Basic Linear Algebra Subprograms} (BLAS) bekannt. Es existieren Wrapper und Portierungen für verschiedene Sprachen.
	
		BLAS besteht aus drei Teilen:
		\begin{itemize}
			\item \textbf{Level 1: Vektor-Vektor Operationen}\\
			Normen, Skalarprodukte, Dotprodukte, Kreuzprodukte, ...
			\item \textbf{Level 2: Matrix-Vektor Operationen}\\ Multiplikationen von Vektoren und Matrizen unter Nebenbedingungen (z.B. symmetrische Matrix, ...)
			\item \textbf{Level 3: Matrix-Matrix Operationen}\\Matrixnormen, Matrixadditionen, Matrixmultiplikationen unter Nebenbedingungen, ...
		\end{itemize}
		
		Es existiert eine Implementierung von Nvidia in CUDA namens cuBLAS. In dieser Bibliothek, die Teil des CUDA Toolkits ist, werden diese Operationen auf der GPU parallelisiert. Zur Benutzung muss der Header \textit{cublas{\_}v2.h} (in älteren Versionen \textit{cublas.h}) inkludiert und mit \textit{libcublas} gelinkt werden.
		
		Die Handhabung soll möglichst einfach gehalten werden. Der Anwender implementiert Vektoren als gewöhnliche Arrays und linearisierte Matrizen ebenfalls als Array. Für komplexe Zahlen existiert das Datenformat \li`cuComplex` (\li`cuDoubleComplex`), welches analog zu \li`cufftComplex` (\li`cufftDoubleComplex`) funktioniert. In cuBLAS geht man von column-major Format und 1-based indexing aus. Dabei wird eine Matrix spaltenweise nacheinander in einem Array abgelegt. Dann ist für ein Element einer Matrix $A(i,j)$ (wobei $i$ und $j$ mit 1 beginnen) der Index im Array \li`A[(j-1)*m + i-1]`, wobei $m$ die Anzahl an Reihen einer Matrix ist. 
		
		\begin{lstlisting}[caption=cuBLAS: Matrix setzen]
		#define IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))
		
		uint M = ...;
		uint N = ...;	

		float* a = (float *)malloc (M * N * sizeof(float));
		for (uint j = 1; j <= N; j++) 
		{
			for (uint i = 1; i <= M; i++) a[IDX2F(i,j,M)] = ...;
		}
		float *b = ...; float *c = ...;

		float* devPtrA;
		cudaMalloc(&devPtrA, M*N*sizeof(float));

		float* devPtrA;
		float* devPtrB;
		float* devPtrC;
		cublasSetMatrix(M, N, sizeof(float), a, M, devPtrA, M);
		...
		\end{lstlisting}
		
		Sobald die Objekte gesetzt wurden, wird ähnlich wie in cuFFT ein \Gls{Handle} erstellt. Dann können auf diesen Objekten bestimmte Operationen ausgeführt werden, deren Namen und Handhabung in Kapitel 2.4 der cuBLAS Dokumentation \autocite{cublasDoc} nachgeschlagen werden können. In den meisten Fällen existieren Funktionen in mehreren Versionen für verschiedenen Präzisionen. Nach Ausführung kann das Objekt zur Ausgabe in den CPU Speicher zurück kopiert werden. Typischerweise implementieren diese Funktionen eine Abfolge von mehreren Operationen, die auf eine spezielle Operation angepasst werden muss.
		
		Man betrachte die Berechnung einer Matrixmultiplikation $C = A\cdot B$ einer $m\times n$ Matrix $A$ und einer $n\times m$ Matrix $B$ im allgemeinen Fall für einfache Präzision. Dafür existiert die Funktion \li`cublasSgemm`. Diese implementiert die Abbildung $C \leftarrow \alpha\cdot\textbf{op}(A)\textbf{op}(B) + \beta\cdot C$, wobei \li`op()` für Transponieren oder Konjugieren stehen kann und $\alpha$ bzw. $\beta$ beliebige Skalare sind. Für \li`op()` existiert der Datentyp \li`cublasOperation_t` und kann entweder \li`CUBLAS_OP_N` (\enquote{normal}), \li`CUBLAS_OP_T` (\enquote{transponiert}) oder \li`CUBLAS_OP_C` (\enquote{komplex konjugiert}) sein. In diesem Beispiel muss also die Funktion wie folgt gerufen werden: 
		
		\begin{lstlisting}[caption=cuBLAS: Funktionsaufruf]
		cublasHandle_t handle;
		cublasCreate(&handle);
		
		cublasSgemm(handle, 
			CUBLAS_OP_N , CUBLAS_OP_N, M, M, N, 
			1.0, devPtrA, M, devPtrB, N, 
			0.0, devPtrC, M);
		
		cublasGetMatrix(M, M, sizeof(float), devPtrC, M, c, M);
		
		cudaFree(devPtrA); cudaFree(devPtrB); cudaFree(devPtrC);			
		free(a); free(b); free(c);
		
		cublasDestroy(handle);
		\end{lstlisting}
		
		Zunächst muss eine $m\times m$ Matrix $C$ mit null vorbelegt werden. Die Größen von $A$ und $B$ müssen richtig angegeben und mit der Operation \li`CUBLAS_OP_N` versehen werden. Dazu wird nach dem Devicepointer der Matrix die Leading Dimension angegeben. Die zweite Dimension ergibt sich aus der Gesamtgröße des Arrays. Zudem müssen Länge und Breite noch einmal explizit angegeben werden, um evtl. nur eine Submatrix zu multiplizieren. Skalar $\alpha$ wird auf eins, $\beta$ auf null gesetzt. 
		
		In älteren Versionen sind Wrapper für die Allozierungsfunktionen vorhanden. Diese gelten als veraltet und sollten nicht mehr verwendet werden.
		
		Es existiert eine von AMD entwickelte Portierung clBLAS für OpenCL. Wie gewohnt ist diese Bibliothek quelloffen und kann unter \url{https://github.com/clMathLibraries/clBLAS} heruntergeladen werden. Auch diese Library wurde für AMD GPUs optimiert, lässt sich aber auch auf anderen Geräten verwenden. Eine Dokumentation steht ebenfalls zur Verfügung \autocite{clblasDoc}. Nach Installation muss der Header \textit{clblas.h} inkludiert und mit \textit{libclBLAS} (und wie gewohnt mit \textit{libOpenCL}) gelinkt werden.

		Zur Benutzung muss eine Initialisierungsfunktion gerufen werden. Matrizen werden ebenfalls im column-major Format in einen Buffer geschrieben. Da sich clBLAS ebenfalls an BLAS orientiert, unterscheiden sich die Namen der Funktionen gegenüber cuBLAS nur im Präfix \enquote{cl}. Nach Ausführen dieser Funktion muss synchronisiert und das Ergebnis zurück kopiert werden.\\ \\
		\begin{lstlisting}[caption=clBLAS Beispiel]
		cl_int err;
		cl_uint M = ...; cl_uint N = ...;
		
		cl_float *A = ...; cl_float *B = ...; cl_float *C = ...;
		
		clblasSetup();
		
		cl_mem bufA = clCreateBuffer(ctx, CL_MEM_READ_ONLY,  
			M*N * sizeof(cl_float), NULL, &err); 
		cl_mem bufB = ...; cl_mem bufC = ...;

		clEnqueueWriteBuffer(queue, bufA, CL_TRUE, 0, 
			M*N * sizeof(cl_float), A, 0, NULL, NULL);       
		 
		cl_event event;
		clblasSgemm(clblasColumnMajor, clblasNoTrans, clblasNoTrans, M, M, N,
			1.0, bufA, 0, M, bufB, 0, N, 
			0.0, bufC, 0, M,
			1, &queue, 0, NULL, &event);
		clWaitForEvents(1, &event);

		clEnqueueReadBuffer(queue, bufC, CL_TRUE, 0, 
			M*M * sizeof(cl_float), C, 0, NULL, NULL);

		clReleaseMemObject(bufC);clReleaseMemObject(bufB);clReleaseMemObject(bufA);
		clblasTeardown();
		\end{lstlisting}
		
		Einziger Unterschied zu cuBLAS ist die Angabe von OpenCl-spezifischen Eigenheiten, wie z.B. die Angabe eines Offsets oder	
der Events.
		
		\subsection{cuSPARSE und clSPARSE}
		In vielen Fällen der Praxis handelt es sich bei Matrizen um sogenannte dünn besetzte Matrizen (engl. \textit{sparse matrices}). Das Prinzip eines sparse-Formates beruht darauf, die wesentliche Anzahl von Nullen in der Matrix nicht zu speichern. Man speichert lediglich die von null verschiedenen Werte und deren Indizes in der Matrix. Bei einer Bandmatrix z.B. steigt die Zahl dieser Elemente linear mit $n$, die Zahl der Nullen aber quadratisch. Daher ist in den meisten Fällen ein solches Format bereits wegen dem geringeren Speicherbedarf sinnvoll. 
		
		Eine Multiplikation mit Null ergibt immer Null und muss nicht explizit ausgeführt werden. Um die Performance zu steigern, müssen folglich Algorithmen verwendet werden, die dieses Format explizit unterstützen. Für CUDA existiert die Bibliothek cuSPARSE. Das Inkludieren und Linken erfolgt wie gewohnt (\textit{cusparse.h}, \textit{libcusparse}).
		
		Folgendes Beispiel zeigt die Erstellung einer Matrix im \textit{Coordinated Format} (COO). Wie bei cuBLAS existiert auch hier kein expliziter Datentyp. Für die Matrixwerte und die Indizes werden eigene Arrays erstellt und manuell belegt.	
		\begin{lstlisting}[caption=cuSPARSE: Matrix erstellen]
		int n   = ...; int nnz = ...;
		int *cooRowIndexHostPtr =    (int*)malloc(nnz*sizeof(int));
		int *cooColIndexHostPtr =    (int*)malloc(nnz*sizeof(int));
		double *cooValHostPtr   = (double*)malloc(nnz*sizeof(double));

		//Beispiel (COO Format): 
		cooRowIndexHostPtr[0]=0; cooColIndexHostPtr[0]=0; cooValHostPtr[0]=1.0;
		cooRowIndexHostPtr[1]=0; cooColIndexHostPtr[1]=2; cooValHostPtr[1]=2.0;
		...		
		\end{lstlisting}

		Bei diesem Format werden die Werte und deren Indizes in der Matrix nacheinander, ohne Ordnung und zeilenweise abgelegt. Es existieren komplexere Formate, die für bestimmte Algorithmen notwendig sind. Für die Operation aus dem letzten Abschnitt wird beispielsweise das \textit{Block Compressed Sparse Row Format} (BSR) Format benötigt. Die genauen Anforderungen der Formate können in der Dokumentation nachgelesen werden. \cite{cusparseDoc}
		Für Vektoren ist die Angabe eines zweiten Index natürlich überflüssig. Dichte Vektoren werden als gewöhnliche Arrays gespeichert.
		\begin{lstlisting}[caption=cuSPARSE: Vektor erstellen]
		int nnz_vector = ;
		int    *xIndHostPtr =    (int*)malloc(nnz_vector*sizeof(int));
		double *xValHostPtr = (double*)malloc(nnz_vector*sizeof(double));
    
		double *yHostPtr    = (double*)malloc(2*n       *sizeof(double));
    
		double *zHostPtr    = (double*)malloc(2*(n+1)   *sizeof(double));
		\end{lstlisting}

		Sämtliche Arrays müssen wie üblich auf der Grafikkarte alloziert und vom Host kopiert werden. Danach wird ein \gls{Handle} und ein Matrix Deskriptor erstellt, der eine Datenstruktur für das Device aufbaut. Die Angabe des Matrixtyps und der Art der Indizierung ist dabei erforderlich. Für Ersteres existieren folgende Möglichkeiten:
		\begin{itemize}
			\item CUSPARSE{\_}MATRIX{\_}TYPE{\_}GENERAL
			\item CUSPARSE{\_}MATRIX{\_}TYPE{\_}SYMMETRIC
			\item CUSPARSE{\_}MATRIX{\_}TYPE{\_}HERMITIAN
			\item CUSPARSE{\_}MATRIX{\_}TYPE{\_}TRIANGULAR
		\end{itemize}

		Dadurch lassen sich beim Speichern redundante Informationen vermeiden.

		Die Library implementiert zudem einige Konvertierungsfunktionen, z.B. vom COO ins CSR Format. Wichtig ist die Angabe von \li`nnz`, die Anzahl der von null verschiedenen Elemente.

		\newpage		
		
		\begin{lstlisting}[caption=cuSPARSE: Initialisierung und Konvertierung]
		//Malloc und Memcopy
		...

		cusparseHandle_t handle;
		cusparseCreate(&handle);

		cusparseMatDescr_t descr;
		cusparseCreateMatDescr(&descr);
		cusparseSetMatType(descr,CUSPARSE_MATRIX_TYPE_GENERAL);
		cusparseSetMatIndexBase(descr,CUSPARSE_INDEX_BASE_ZERO);
    
		int *csrRowPtr; 
		cudaMalloc(&csrRowPtr, (n+1)*sizeof(int));
		cusparseXcoo2csr(handle, cooRowIndex, nnz, n, 
		                 csrRowPtr, CUSPARSE_INDEX_BASE_ZERO);
		\end{lstlisting}

		Auch hier existieren drei Level an Operationen.
		\begin{itemize}
			\item \textbf{Level 1: sparseVektor - denseVektor Operationen}\\
			\item \textbf{Level 2: sparseMatrix - denseVektor Operationen}\\
			\item \textbf{Level 3: sparseMatrix - mehrere Vektoren gespeichert als denseMatrix}
		\end{itemize}
		
		Bei Letzterem werden die Vektoren nacheinander im selben Array abgespeichert. Im Folgenden wird jeweils ein Beispiel gezeigt. 
		
		\begin{lstlisting}[caption=cuSPARSE: Beispiele und Cleanup]
		//Level 1
		cusparseDsctr(handle, nnz_vector, xVal, xInd, 
		              &y[n], CUSPARSE_INDEX_BASE_ZERO);


		//Level 2
		cusparseDcsrmv(handle,CUSPARSE_OPERATION_NON_TRANSPOSE, n, n, nnz,
		               &number, descr, cooVal, csrRowPtr, cooColIndex, 
		               &y[0], &number, &y[n]);

		//Level 3
		double *z; cudaMalloc(&z,   2*(n+1)*sizeof(double));
		cudaMemset(z, 0, 2*(n+1)*sizeof(double));
		cusparseDcsrmm(handle, CUSPARSE_OPERATION_NON_TRANSPOSE, n, 2, n,
		               nnz, &number, descr, cooVal, csrRowPtr, cooColIndex, 
		               y, n, &number, z, n+1);
               
		cusparseDestroyMatDescr(descr);
		cusparseDestroy(handle);
		\end{lstlisting}

		\Gls{Handle} und Deskriptor müssen explizit zerstört werden. Wie gewohnt müssen Arrays auf Host und Device freigegeben werden.

		\subsection{cuSOLVER}
		Es existiert eine Reihe von Bibliotheken, die aufbauend auf BLAS die wichtigsten Algorithmen der linearen Algebra implementieren, z.B. QR-Zerlegung oder Eigenwertberechnung. Die bekannteste ist das \textit{Linear Algebra Package} (LAPACK), das in Fortran77 geschrieben wurde (umgeschrieben auf Fortran90) und für die meisten Programmiersprachen portiert wurde. Es existieren hierfür auch \Glspl{API}, z.B. Armadillo oder JLapack.
		Um für dicht und dünn besetzte Matrizen schnelle Methoden für Berechnungen in der linearen Algebra bereit zu stellen, existiert eine Implementierung der wichtigsten Algorithmen in der Bibliothek cuSOLVER, ein Teil des CUDA Toolkits. Linken und Inkludieren erfolgt wie gewohnt (\textit{cusolver.h}, \textit{libcusolver}). Diese Bibliothek orientiert sich an LAPACK und besteht aus drei Teilen:
		\begin{itemize}
		    \item \textbf{cuSolverDN: Dense LAPACK} 
		
		    Methoden zur Lösung eines regulären dicht besetzten Gleichungssystems $Ax = b$ (QR- und LU-Zerlegung mit Pivotisierung, Cholesky Zerlegung für symmetrisch/hermitesche Matrizen, Bunch-Kaufmann-Zerlegung für symmetrisch indefinite Matrizen, Singulärwertzerlegung).

		    \newpage
		    
	        	\item \textbf{cuSolverSP: Sparse LAPACK}
		
		    Methoden zur Lösung eines dünn besetzten Gleichungssystems $Ax = b$, im nicht regulären Fall durch least-square Regression $x = \text{argmin}||Az-b||$. Für symmetrische Matrizen muss eine volle Matrix angegeben werden (Ausnahme: Bei Cholesky-Zerlegung reicht die untere linke Dreiecksmatrix.) Zusätzlich existiert eine Eigenwertzerlegung auf Basis der shift-inverse-power Methode. 
		
		    \item \textbf{cuSolverRF: Refactorization}
		
		    Methoden zur schnellen Lösung einer Menge von Gleichungssystemen $A_i x_i = b_i$. Bleibt das sparsity-pattern\footnote{Position der von null verschiedenen Elemente} der Matrizen $A_i$, sowie das Neuordnen zur Pivotisierung und zum Auffüllen während der LU-Zerlegung gleich, ist dieser Teil der Bibliothek anwendbar. Zuerst wird für $i=1$ eine volle LU-Zerlegung durchgeführt. Für die folgenden kann ein LU-Refaktorisierungsalgo-rithmus verwendet werden.	
		\end{itemize}
		Jede Operation ist grundsätzlich für die Datentypen \li`float`, \li`double`, \li`cuComplex`, und \li`cuDoubleComplex` implementiert. Für die Funktionen gelten bestimmte Namenskonventionen. Für Dense:
		
		\li`cusolverDn<t><operation>` 

		Der Datentyp wird mit \li`<t>` angegeben, S (single), D (double), C (complex single), Z (complex double) und X (generic). 
		
		Für Sparse:
		
		\li`cusolverSp[Host]<t>[<matrix data format>]<operation>[<output matrix data format>]<based on>`
		
		Die Angabe \li`[Host]` steht für die CPU-Implementierung. \li`[<matrix data format>]` steht für die Angabe des sparse-matrix Formats (z.B. \li`csr`). \li`[<output matrix data format>]` ist entweder \li`m` oder \li`v` für Matrix oder Vektor. \li`<based on>` beschreibt den Algorithmus (z.B. \li`qr`).
		
		Im Folgenden soll die Lösung eines regulären linearen Gleichungssystems $A_{m\times m}x=B$ mittels LU-Zerlegung ermittelt werden.
		
		\begin{lstlisting}[caption=cuSOLVER: Buffer]
		const int m = ...; const int lda = m; const int ldb = m;
		float A[lda*m] = {...};
		float B[m] = {...};    

		cusolverDnHandle_t cusolverH; cusolverDnCreate(&cusolverH);
		cudaStream_t stream;
		cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking);
		cusolverDnSetStream(cusolverH, stream);

		float *d_A; cudaMalloc(&d_A, sizeof(float)*lda*m);
		float *d_B; cudaMalloc(&d_B, sizeof(float)*m);

		cudaMemcpy(d_A, A, lda*m*sizeof(float), cudaMemcpyHostToDevice);
		cudaMemcpy(d_B, B,     m*sizeof(float), cudaMemcpyHostToDevice);

		int lwork; float *d_work; 
		cusolverDnDgetrf_bufferSize(cusolverH, m, m, d_A, lda, &lwork);
		cudaMalloc(&d_work, sizeof(float)*lwork);
		\end{lstlisting}
		
		Für die Nutzung der Funktionen muss ein \Gls{Handle} erzeugt und einem \Gls{Stream} hinzugefügt werden. Belegen der Matrizen erfolgt wie gewohnt linearisiert. Allerdings muss danach mit \\ \li`cusolverDnDgetrf_bufferSize` die Größe eines Buffers, der für die Zerlegung notwendig ist, ermittelt werden. Mit dieser Angabe wird dann der Buffer explizit angelegt.
		
		\begin{lstlisting}[caption=cuSOLVER: LU-Zerlegung]
		int Ipiv[m]; int info; 
		int *d_Ipiv; cudaMalloc(&d_Ipiv, m*sizeof(int));
		int *d_info; cudaMalloc(&d_info,   sizeof(int));
		
		const int pivot_on = 1;
		if(pivot_on) 
			cusolverDnDgetrf(cusolverH, m, m, d_A, lda, d_work, d_Ipiv, d_info);
		else          
			cusolverDnDgetrf(cusolverH, m, m, d_A, lda, d_work, NULL,   d_info);
		cudaDeviceSynchronize();

		float LU[lda*m];
		if(pivot_on) 
			cudaMemcpy(Ipiv, d_Ipiv, m*sizeof(int), cudaMemcpyDeviceToHost);
		cudaMemcpy(LU, d_A, lda*m*sizeof(float), cudaMemcpyDeviceToHost);
		cudaMemcpy(&info, d_info, sizeof(int), cudaMemcpyDeviceToHost);

		if(0 > info) printf("%d-th parameter is wrong \n", -info);
		\end{lstlisting}
		
		Nun kann explizit eine LU-Zerlegung $A = LU$ mittels \li`cusolverDnDgetrf` durchgeführt werden. Dies funktioniert optional mit einer Pivotisierung $PA = LU$ (Permutationsmatrix $P$), bei der zusätzlich das Pivot Element jeder Zeile gespeichert wird. Bei dem speziellen Info \enquote{Array} \li`d_info` handelt es sich um einen einzigen globalen Integer-Wert, der mit negativem Vorzeichen angibt, welcher Parameter bei der Berechnung fehlerhaft war. Bei einer fehlerfreien Berechnung ist dieser Wert mit null belegt. Die Ausgabe der fertige Zerlegung wird als $(L-1)+U$ in einer einzigen Matrix gespeichert.
		
		\begin{lstlisting}[caption=cuSOLVER: Gleichungssystem lösen]
		if(pivot_on) 
			cusolverDnDgetrs(cusolverH, CUBLAS_OP_N, m, 1, d_A, lda, 
			    d_Ipiv, d_B, ldb, d_info);
		else         
			cusolverDnDgetrs(cusolverH, CUBLAS_OP_N, m, 1, d_A, lda, 
			    NULL,   d_B, ldb, d_info);
			
		cudaDeviceSynchronize();

		float X[m];
		cudaMemcpy(X, d_B, m*sizeof(float), cudaMemcpyDeviceToHost);

		cudaFree(d_A); cudaFree(d_B); cudaFree(d_Ipiv);
		cudaFree(d_info); cudaFree(d_work);

		cusolverDnDestroy(cusolverH);
		cudaStreamDestroy(stream);
		\end{lstlisting}
		
		Der Aufruf führt \li`cusolverDnDgetrs` (wahlweise mit Pivotisierung) eine Vor- und Rückwärtssubstitution aus und berechnet so die Lösung des Gleichungssystems ($Ly = B$, $Ux = y$). Das Ergebnis steht in \li`d_B` bereit.
		
		Für eine Operation aus Level 2 muss eine dünne Matrix im richtigen Format analog zu cuSPARSE erstellt werden. Dann wir ein entsprechender \Gls{Handle} mit \li`cusolverSpHandle_t` erstellt und die entsprechende Funktion ausgeführt. Da dies recht aufwändig ist und keinen großen Mehrwert bietet, soll hier darauf verzichtet werden.
		
		\subsection{MAGMA}
		Die zunehmende Notwendigkeit, Algorithmen auf heterogenen Systemen zu parallelisieren, motivierte die Entwicklung der \textit{Matrix Algebra on GPU and Multicore Architectures} (MAGMA). MAGMA orientiert sich in der Funktionsweise an BLAS bzw. LAPACK und soll effiziente Algorithmen implementieren, die die Hardware eines heterogenen Systems (gleichzeitig Vielkernprozessor und verschiedene GPUs) vollständig ausreizen. Bei Installation wird Existenz und Version von CUDA und OpenMP abgefragt. Dann wird die Bibliothek für alle relevanten Architekturen und Konfigurationen kompiliert. Linken erfolgt dann gegen \textit{libmagma} oder \textit{libmagma{\_}sparse} und gegen die entsprechenden Abhängigkeiten (\textit{liblapack}, \textit{libcuBLAS}, ...). Inkludiert wird \textit{magma{\_}v2.h} für die BLAS- und \textit{magma{\_}lapack.h} für die LAPACK-Portierung.

		Es existieren zwei Interfaces. Falls keine Grafikkarte zur Verfügung steht, kann das CPU-Interface benutzt werden. In diesem Fall wird ein OpenMP parallelisierter Algorithmus verwendet. Andernfalls kann mittels GPU-Interface ein mit CUDA beschleunigter Hybridalgorithmus verwendet werden. Sollte trotz vorhandener GPU (und GPU-Installation) das CPU-Interface benutzt werden, wird dennoch ein Hybridalgorithmus verwendet.
		
		Im Folgenden soll die LU-Zerlegung in cuSOLVER mit MAGMA durchgeführt werden.
		
		\begin{lstlisting}[caption=MAGMA: CPU-Interface]
		magma_init();
		magma_queue_t queue;
		magma_int_t  dev = 0;
		magma_queue_create(dev, &queue);
  
		magma_int_t m = ...; magma_int_t n = 1;
                      
                      
		float *a; magma_smalloc_pinned(&a, m*m);   
		float *b; magma_smalloc_pinned(&b, m);  
		float *x; magma_smalloc_pinned(&x, m);   
		magma_int_t *piv = (magma_int_t *)malloc(m*sizeof(magma_int_t));
		
		//Belegen...

		const float alpha = 1.0f;
		const float beta  = 0.0f;
		blasf77_sgemm("N", "N", &m, &n, &n, &alpha, a, &m, x, &m, &beta, b, &m);


		magma_int_t info;
		magma_sgesv(m, n, a, m, piv, b, m, &info);

		magma_free_pinned(a); magma_free_pinned(b); magma_free_pinned(x); free(piv);

		magma_queue_destroy(queue);
		magma_finalize();
		\end{lstlisting}
		
		Zunächst wird MAGMA initialisiert. Danach wird ein Device ausgewählt und einer Command Queue hinzugefügt. Bei der Verwendung des CPU Interfaces für einen GPU Algorithmus wird managed Memory verwendet. Daher muss für die Arrays pinned Memory (page-locked) alloziert werden. Danach erfolgt ein Aufruf einer Matrixmultiplikation analog zu cuBLAS \mbox{(\li`blasf77_sgemm`)}, um die Lösung später überprüfen zu können. Die Zerlegung selbst erfolgt dann analog zu cuSOLVER mittels \li`magma_sgesv`.	
		
		\begin{lstlisting}[caption=MAGMA: GPU-Interface]
		magma_init();
		magma_queue_t queue;
		magma_int_t  dev = 0;
		magma_queue_create(dev, &queue);
  
		magma_int_t m = ...; magma_int_t n = 1;
                      
		float *a; magma_smalloc_cpu(&a, m*m);   
		float *b; magma_smalloc_cpu(&b, m);  
		float *x; magma_smalloc_cpu(&x, m);   
		magma_int_t *piv = (magma_int_t *)malloc(m*sizeof(magma_int_t));
		
		//Belegen...

		const float alpha = 1.0f;
		const float beta  = 0.0f;
		blasf77_sgemm("N", "N", &m, &n, &n, &alpha, a, &m, x, &m, &beta, b, &m);

		////////////////////////////////////////////
		
		float *d_a; magma_smalloc(&d_a, m*m);
		float *d_b; magma_smalloc(&d_b, m);		
		magma_ssetmatrix(m, m, a, m, d_a, m, queue);
		magma_ssetmatrix(m, n, b, m, d_b ,m, queue);
		
		////////////////////////////////////////////

		magma_int_t info;
		magma_sgesv_gpu(m, n, d_a, m, piv, d_b, m, &info);
		
		////////////////////////////////////////////
		
		magma_sgetmatrix(m, n, d_b, m, x, m, queue);
		magma_free(d_a); magma_free(d_b);
		
		////////////////////////////////////////////
		
		free(a); free(b); free(x); free(piv);
		
		magma_queue_destroy(queue);
		magma_finalize();
		\end{lstlisting}
		
		Das GPU Interface funktioniert an sich ähnlich, es müssen lediglich Arrays explizit vom Host auf das Device kopiert werden. Daher kann nun der CPU Speicher gewöhnlich mit \li`magma_smalloc_cpu` $\!\!$alloziert werden. GPU Speicher wird mit \li`magma_smalloc` erzeugt und mit \li`magma_ssetmatrix` bzw. \li`magma_sgetmatrix` kopiert. Der Aufruf der LU-Zerlegung \li`magma_sgesv_gpu` ist beinahe identisch. CPU Speicher wird normal mit \li`free`, GPU Speicher mit \li`magma_free` freigegeben.	
		
		MAGMA implementiert ebenfalls Algorithmen für dünne Matrizen. Aus bekannten Gründen wird hier jedoch nicht weiter darauf eingegangen.
		
		\subsection{Iterative Verfahren}
		Bei den Verfahren aus BLAS und LAPACK handelt es sich um direkte Lösungsverfahren. Diese liefern im Erfolgsfall (bis auf numerische Ungenauigkeiten) die analytische Lösung. Bei den sogenannten iterativen Verfahren handelt es sich um numerische Lösungen ähnlicher Probleme, deren Genauigkeit aber durch die Abbruchbedingung der Iteration gesteuert werden kann. Man opfert also Genauigkeit zu Gunsten von Performance. 
		
			\subsubsection{Paralution}
			Paralution ist eine sehr umfangreiche C++-Bibliothek für indirekte (sparse) Lösungsverfahren von Differentialgleichungen oder Problemen der linearen Algebra. Im folgenden Beispiel soll die zweidimensionale stationäre Wärmeleitungsgleichung $\Laplace x = b$ auf einem diskretisierten $100\times 100$ Gitter gelöst werden. $x$ bezeichnet die Temperatur, $b$ eine Inhomogenität.
			\begin{lstlisting}[caption=Paralution Beispiel]		
			paralution::init_paralution();
			paralution::info_paralution();

			paralution::LocalVector<float> x;
			paralution::LocalVector<float> rhs;

			paralution::LocalStencil<float> stencil(Laplace2D);
			stencil.SetGrid(100);

			x.Allocate("x", stencil.get_nrow()); x.Zeros();
			rhs.Allocate("rhs", stencil.get_nrow()); rhs.Ones();

			paralution::CG<LocalStencil<float>, LocalVector<float>, double> ls;
			ls.SetOperator(stencil);
			ls.Build();
			stencil.info();

			ls.Solve(rhs, &x);

			paralution::stop_paralution();
			\end{lstlisting}
			
			Die Daten werden hier mit Konstruktoraufrufen von C++ Vektoren erzeugt. Deren Inhalte werden durch explizite Aufrufe von Member-Funktionen gesetzt. Dann wird ein sogenannter Stencil als numerische Näherung für den 2d-Laplace Operator erzeugt. Das Gitter, auf welches dieser Stencil angewendet werden soll, wird auf 100 ($100\times 100$) gesetzt. Damit wird ein linear Solver (ls) erzeugt (\li`ls.Build()`). Mit diesem kann die Differentialgleichung nun gelöst werden (\li`ls.Solve(rhs, &x)`). An Stelle eines Laplace Operators lässt sich genauso eine Matrix verwenden, um beispielsweise eine Zerlegung auszuführen. Mit der Initialisierungsfunktion \li`init_paralution` können mehrere Parameter, wie z.B. die Abbruchbedingung der Iteration eingestellt werden. Dies kann im äußerst ausführlichen Handbuch nachgeschlagen werden. \autocite{para}
			 
			\subsubsection{AMGX}	
			Bei AmgX handelt es sich um eine ähnliche Bibliothek. Die Stärken liegen hierbei u.A. bei Krylov-Subspace Methoden. AmgX ist ein offizielles Partnerprojekt von Nvidia und kann unter \url{https://github.com/NVIDIA/AMGX} heruntergeladen werden. Zusätzliche Python Bindings sind unter \url{https://github.com/shwina/pyamgx} verfügbar. Das Handbuch enthält mehr Informationen über die Nutzung. \autocite{amgx}	
			
		\subsection{clSPARSE}
		Ein Teil von cuSPARSE und cuSOLVER sowie zusätzliche iterative Verfahren wurden von AMD in OpenCL als clSPARSE implementiert. Das \Gls{API} wurde vollständig in C++ programmiert und ist kompatibel zum OpenCL C++ Wrapper. Die Bibliothek enthält folgende Funktionen:
		
		\begin{itemize}				
			\item Sparse Matrix - dense Vector multiply (SpM-dV)
			\item Sparse Matrix - dense Matrix multiply (SpM-dM)
			\item Sparse Matrix - Sparse Matrix multiply Sparse Matrix Multiply(SpGEMM) - Single Precision
			\item Iterative conjugate gradient solver (CG)
			\item Iterative biconjugate gradient stabilized solver (BiCGStab)
			\item Dense to CSR conversions (\& converse)
			\item COO to CSR conversions (\& converse)
			\item Functions to read matrix market files in COO or CSR format
    	    \end{itemize}
    	
        	Folgendes Beispiel implementiert einen iterativen CG-Solver. Dazu werden eine dünne Matrix $A$ sowie zwei dichte Vektoren $x$ und $b$ als C++-Objekte erstellt. Es folgt das Setup und der \Gls{Handle}, hier \textit{Control} genannt. 
        	
        	\newpage
        	
        	\begin{lstlisting}[caption=clSPARSE: Initialisieren]
        cldenseVector x;
        clsparseInitVector(&x);
		
        cldenseVector b;
        clsparseInitVector(&b); 

        clsparseCsrMatrix A;
        clsparseInitCsrMatrix(&A); 
    	
        clsparseSetup();
        clsparseCreateResult createResult = clsparseCreateControl(queue());
        	\end{lstlisting}

		Die Daten der C++ Klasse werden explizit gesetzt. Für die Grafikkarte muss dennoch Speicher alloziert und kopiert werden. Man beachte den eigenen Datentyp \li`clsparseIdx_t`. Das Format der Matrix (CSR) muss dem \Gls{Handle} bekannt gemacht werden (\enquote{Meta}).\\
    	    \begin{lstlisting}[caption=clSPARSE: Vektoren und Matrizen setzen]
		A.num_nonzeros = ...;
		A.num_rows = ...;
		A.num_cols = ...;    
		A.values =      cl::clCreateBuffer(context(), CL_MEM_READ_ONLY, 
		                                   A.num_nonzeros*sizeof(float));

		A.col_indices = cl::clCreateBuffer(context(), CL_MEM_READ_ONLY, 
		                                   A.num_nonzeros*sizeof(clsparseIdx_t));

		A.row_pointer = cl::clCreateBuffer(context(), CL_MEM_READ_ONLY, 
		                                  (A.num_rows + 1)*sizeof(clsparseIdx_t)); 
		
		//Belegen und Kopieren...
                                     
		clsparseCsrMetaCreate(&A, createResult.control);
      
		x.num_values = A.num_cols;
		x.values = clCreateBuffer(context(), CL_MEM_READ_ONLY, 
		                          x.num_values*sizeof(float));
		clEnqueueFillBuffer(queue(), x.values, &number, sizeof(float), 0, 
		                    x.num_values*sizeof(float), 0, nullptr, nullptr);
                                    
		b.num_values = A.num_rows;
		b.values = clCreateBuffer(context(), CL_MEM_READ_WRITE, 
		                          b.num_values*sizeof(float));
		clEnqueueFillBuffer(queue(), b.values, &number, sizeof(float), 0, 
		                          b.num_values*sizeof(float), 0, nullptr, nullptr);
		\end{lstlisting}  
		
		Nach dem Setup kann ein eigener \Gls{Handle} für den Solver erstellt werden. Es wird ein diagonaler Vorkonditionierer verwendet. Die Konverkenzkriterien sind $\varepsilon_{rel} = 10^{-2}$ und $\varepsilon_{abs} = 10^{-5}$. Das Iterationslimit wird auf $1000$ gesetzt. Schließlich wird die eigentliche Funktion gerufen. Beide \Glspl{Handle} werden nach Gebrauch zerstört. Trotz C++ \Gls{API} müssen die Speicherobjekte freigegeben werden. Die Metainformation muss ebenfalls gelöscht werden.
		                    
		\begin{lstlisting}[caption=clSPARSE: Ausführen]
		clsparseCreateSolverResult solverResult = 
			clsparseCreateSolverControl(DIAGONAL, 1000, 1e-2, 1e-5);
		
		clsparseScsrcg(&x, &A, &b, solverResult.control, createResult.control);
		
		clsparseReleaseSolverControl(solverResult.control);
    
		clsparseReleaseControl(createResult.control);
		
		clsparseTeardown();  
		  
		clsparseCsrMetaDelete(&A);
		
		clReleaseMemObject(A.values);
		clReleaseMemObject(A.col_indices);
		clReleaseMemObject(A.row_pointer);

		clReleaseMemObject(x.values);
		clReleaseMemObject(b.values);
        	\end{lstlisting}
    	
    	    Die Dokumentation ist unter \href{http://clmathlibraries.github.io/clSPARSE/} zu finden. Für das Error Handling muss neben dem üblichen \textit{clSPARSE.h} zusätzlich \textit{clSPARSE-error.h} inkludiert werden. Linken erfolgt gegen \textit{libclSPARSE}.
			