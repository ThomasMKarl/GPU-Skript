	\chapter{Einf\"uhrung in OpenCL}
	\textit{Open Computing Language} (OpenCL) ist eine freie open-source Programmierschnittstelle für paralleles Rechnen, die Von Apple im Jahr 2009 entwickelt wurde. Heute liegt diese in Version 2.2 vor und wird von der Khronos Gruppe entwickelt, der sich mittlerweile über 200 Firmen angeschlossen haben. Das Ziel hinter dem Projekt ist es, eine low-level Programmiersprache und Schnittstelle zu schaffen, mit denen sich maximal inhomogene Parallelrechner (CPUs, GPUs, Grafikchips, FPGAs, Beschleuniger, ...) programmieren lassen und dabei Plattformunabhängigkeit gewährleisten. Ein Gerät benötigt dafür eine Hardwareimplementierung und der Hersteller muss eine OpenCL Implementierung in Software bereitstellen (z.B. AMD, Intel, ...). Im Nvidia Toolkit ist eine OpenCL Installation enthalten, in Hardware aber nur für Version 1.2 implementiert. C- und C++-\Glspl{API} sind gewöhnliche Librarys, die unter Linux über die Paketquellen installiert werden können.
	
	Die Khronos Gruppe entwickelt ebenfalls die Grafikbibliothek OpenGL und Nachfolger Vulkan, für die ähnliche Prinzipien gelten. 
	 
	    \section{Begriffe}
	    Obwohl Nvidia ebenfalls Teil der Khronos Gruppe ist, haben sich in der Fachsprache hier andere Begriffe etabliert. Tabelle \ref{tab4:begriffe} zeigt typische OpenCL Begriffe und ihre Entsprechung in CUDA.
	    	\begin{table}[h]
	    		\centering
	    		\begin{tabular}{|l|l|}
	    			\toprule 
	    			\textbf{OpenCL} & \textbf{CUDA} \\ \hline\hline
	    			Workitem & Thread \\
	    			Workgroup & Block \\ \hline
	    			Global Memory & Global Memory \\
	    			Constant Memory & Constant Memory \\
	    			Local Memory & Shared Memory \\
	    			Private Memory & Local Memory \\ \hline
	    			Platform & \textit{keine} \\
	    			Device & Device \\
	    			Context & \textit{keine} \\
	    			Command Queue & Stream \\
	    			Kernel & Kernel \\
	    			Event & Event \\ \hline
	    			Global Work Size & Grid Size \\
	    			Local Work Size & Block Size \\
	    			Work Dimension & Grid/Block Dimension \\
	    			\bottomrule
	    		\end{tabular}
	    		\caption{Typische OpenCL Begriffe und ihre Entsprechung in CUDA}
	    		\label{tab4:begriffe}
	    	\end{table}
	    	Technisch gesehen sind sich AMD und Nvidia Grafikkarten ähnlich. Allerdings nennt AMD die \Glspl{Warp} \Glspl{Wavefront} und deren Größe ist abhängig vom Chip entweder 32 oder 64. Demnach sollte bei entsprechender Größe die Local Work Size, also die Größe einer \Gls{Workgroup}, ein Vielfaches von 32 oder 64 sein. 
	    	
	    	Diese Einführung beschränkt sich auf das Programmieren von GPUs. Die dafür verwendeten Befehle sind CUDA sehr ähnlich und tragen lediglich andere Namen. Tabelle \ref{tab4:begriffe} zeigt eine Auflistung der wichtigsten.
	    	
	    	\begin{table}[h]
	    		\centering
	    		\scalebox{0.9}{%
	    		\begin{tabular}{|l|l|}\toprule
	    			\textbf{OpenCL} & \textbf{CUDA} \\ \hline\hline
					\li`__kernel`, \li`kernel` & \li`__global__` \\
					\li`__constant`, \li`constant` & \li`__constant__` \\
					\li`__global`, \li`global` & \textit{automatisch} \\
					\li`__private`, \li`private` & \textit{automatisch} \\
					\li`__local`, \li`local` & \li`__shared__` \\
\hline					
					\li`get_global_id(0)` & \li`blockIdx.x*blockdim.x + threadIdx.x` \\
					\li`get_global_id(1)` & \li`blockIdx.y*blockdim.y + threadIdx.y` \\
					\li`get_global_id(2)` & \li`blockIdx.z*blockdim.z + threadIdx.z` \\
\hline					
					\li`get_local_size(0)` & \li`blockdim.x` \\
					\li`get_local_size(1)` & \li`blockdim.y` \\
					\li`get_local_size(2)` & \li`blockdim.z` \\
\hline																				
					\li`get_global_size(0)` & \li`griddim.x` \\
					\li`get_global_size(1)` & \li`griddim.y` \\
					\li`get_global_size(2)` & \li`griddim.z` \\
					
					\li`clCreateBuffer(...)` & \li`cudaMalloc(...)` \\
					\li`clEnqueueWriteBuffer(..)` & \li`cudaMemcpy(Async)(..., cudaMemcpyHostToDevice)` \\
					\li`clEnqueueReadBuffer(..)` & \li`cudaMemcpy(Async)(..., cudaMemcpyDeviceToHost)` \\
					\li`clEnqueueNDRangeKernel(..., <Kernel>, ...)`, \li`clSetKernelArg(...)` & \li`<kernelcall><<<...>>>(...)` \\
\hline
					\li`barrier(CLK_LOCAL_MEM_FENCE)` & \li`__syncthreads()` \\
					\li`barrier(CLK_GLOBAL_MEM_FENCE)` & \li`__syncthreads()` \\
					\li`barrier(CLK_IMAGE_MEM_FENCE)`\footnote{wurde in späteren Versionen in \li`work_group_barrier(...)` umbenannt} & \textit{keine} \\ \bottomrule
	    		\end{tabular}}
	    		\caption{Typische OpenCL Befehle/Keywords und ihre Entsprechung in CUDA}
	    		\label{tab4:befehle}
	    	\end{table}
	    	
	    	Für die Nvidia Produktlinien Geforce, Quadro und Tesla existieren bei AMD die Entsprechungen Radeon, Radeon Pro und Radeon Instinct. 
	    	
		\section{Programmiermodell}
		Im Gegensatz zu CUDA fordert OpenCL eine strikte Trennung von Host- und Devicecode in verschiedenen Dateien. Das Hostprogramm wird mittels der OpenCL C-\Gls{API} programmiert (oder C++ Wrapper), bei der es sich um eine gewöhnliche C-Library handelt. Dieses Hostprogramm wird mit einem beliebigen C- oder C++-Compiler übersetzt und unterstützt damit auch die modernste Features beider Programmiersprachen.
		
		Das Deviceprogramm, also die \Gls{Kernel} liegen in einer oder mehrerer seperater Dateien vor, die als String vom Hostprogramm eingelesen werden. Dies hat den Vorteil, dass zu Compilezeit der Inhalt des Programms nicht bekannt sein muss und damit auch nicht verändert wird. Erst zur Laufzeit wird unsichtbar für den Nutzer der OpenCL Compiler gerufen und das OpenCL Programm kompiliert und ausgeführt. Bei einer Änderung eines \Glspl{Kernel} muss das Hostprogramm also nicht noch ein weiteres Mal kompiliert werden.
		
		Devicecode wird in der eigentlichen Programmiersprache OpenCL C geschrieben, die sich im Wesentlichen an C99 orientiert. Teilweise wurde auch C++ unter dem Namen OpenCL C++ implementiert (siehe \ref{OCLC++}). Es folgt eine Auflistung der wichtigsten Einschränkungen:
		\begin{itemize}
		\item keine C99-Standard Header, Ersatz ist der Vorrat von built-in-Funktionen.
		\item Kernel-Zeigerargumente müssen mit \li`__global`, \li`__constant`, oder \li`__local` qualifiziert werden.  
		\item nur \li`__constant`-Zeiger dürfen \li`__constant`-Zeigern zugewiesen werden.
		\item keine Zeiger auf Funktionen.
		\item keine Bitfelder.
		\item keine VLAs (variable length arrays).
		\item weder Makros noch Funktionen mit variabler Argumentzahl (außer \li`enqueue_kernel`).
		\item keine auto und register Speicherklassen.
		\item keine rekursiven Funktionen.
		\item \Glspl{Kernel} sind immer Prozeduren mit \li`void`-Ergebnis.
		\item keine \Gls{Kernel}-Argumente mit den Typen \li`bool`, \li`half`, \li`size_t`, \li`ptrdiff_t`, \li`intptr_t`, \li`uintptr_t`, sowie Strukturen und Unions mit einer dieser Komponenten.
		\item keine Arithmetik für \li`half`, nur Speicherformat.
		\item irreduzible Anweisungsgruppen (z.B. Sprünge in Schleifen) sind implementation-defined.
		\item \li`const`, \li`restrict` und \li`volatile` sind erlaubt, aber für Images verboten.
		\item \li`event_t` darf kein \Gls{Kernel}-Argument sein.
		\item  \li`event_t` darf nicht zusammen mit \li`__local`, \li`__constant` and \li`__global` verwendet werden.
		\end{itemize}
		
			\subsection{Platformen}
			Da mehrere Verschiedene Implementierungen von OpenCL existieren, muss zunächst eine \Gls{Platform} ausgewählt werden. Die Khronos Gruppe aktualisiert stetig die Liste aller Platformen: \url{https://www.khronos.org/conformance/adopters/conformant-products/opencl}
			\newpage
			\begin{lstlisting}[caption=~Platformabfrage]
			cl_platform_id platform_id = NULL;
			cl_uint ret_num_platforms;
			clGetPlatformIDs(1,&platform_id, &ret_num_platforms);
			\end{lstlisting}

			\li`platform_id` kann bei mehreren Platformen ein Array von IDs sein. In diesem Fall muss im ersten Argument angegeben werden, nach wie vielen Platformen gesucht werden soll.
			
			Die meisten \Gls{API} Aufrufe geben einen Fehlercode zurück, der in einer Tabelle nachgeschlagen werden kann: \url{https://streamhpc.com/blog/2013-04-28/opencl-error-codes/}
			
			Im Folgenden werden nur die OpenCL eigenen Datentypen verwendet (siehe \ref{makros}).					
			\subsection{Devices}
			Jede \Gls{Platform} stellt OpenCL für ein oder auch mehrere Geräte zur Verfügung. Im nächsten Schritt müssen also die entsprechenden Devices den gefundenen \Glspl{Platform} zugeordnet werden.		\begin{lstlisting}[caption=~Deviceabfrage]
			cl_device_id device_id = NULL;	
			clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_DEFAULT, 1, 
				&device_id, &ret_num_devices);
			\end{lstlisting}
			Auch hier kann \li`device_id` ein Vektor sein. Für den Typ des Geräts existieren folgende Möglichkeiten:
				
			\subsection{Kontexte}
			Ein \Gls{Kontext} ist ein \Gls{Handle} für das OpenCL Programm. Dieser beinhaltet Speicherobjekte, Programme und Command Queues. Folglich müssen diese also einem neu erstellten \Gls{Kontext} zugeordnet werden. Abbildung \ref{4:class} zeigt die Zusammenhänge sämtlicher OpenCL Klassen \autocite{oclRC} basierend auf Unified Modelling Language (UML). \autocite{uml}
			\begin{lstlisting}[caption=~Kontexte]
			cl_int ret;
			cl_context context = clCreateContext(NULL, 1, &device_id, 
				NULL, NULL, &ret);	
			\end{lstlisting}
			Sollte eine Funktion über einen eigenen Rückgabewert verfügen, so ist das letzte Argument üblicherweise eine Referenz auf einen Fehlercode.
			\begin{figure}[h]
				\centering
				\includegraphics[width=0.7\textwidth]{/home/kat10110/script/chapter4/pictures/class.jpg}
				\caption{Zusammenhänge sämtlicher OpenCL Klassen}
				\label{4:class}
			\end{figure}				
				
			\subsection{Programme}
			Als nächstes muss das OpenCL Programm als String gelesen, zur Laufzeit kompiliert und dem Kontext hinzugefügt werden. 
			\begin{lstlisting}[caption=~OpenCL Programm]
			FILE *fp;
			char *source_str;
			size_t source_size;
			fp = fopen("cl_vecadd.cl", "r");
			if(!fp)
			{
				fprintf(stderr, "Failed to load the kernel!\n");
				exit(1);
			}
			fseek(fp, 0, SEEK_END);
			size_t s = ftell(fp);
			fseek(fp, 0, SEEK_SET); 
			source_str = (char*)malloc(s);
			source_size = fread(source_str, 1, s, fp);
			fclose(fp);
			
			cl_program program = clCreateProgramWithSource(context, 1, (const char **)&source_str, (const size_t *)&source_size, &ret);
			\end{lstlisting}
			
			Mittels \li`clBuildProgram(program, 1, &device_id, "-D name=definition -I dir", NULL, NULL)` lassen sich ähnlich dem C-Compiler dem OpenCl Compiler zusätliche Informationen mitgeben. So lässt sich der Include-Pfad erweitern. Außerdem können mit -D Makros gesetzt werden. Eine Auflistung voreingestellter Makros findet sich in Kapitel \ref{makros}.
			
			Das vorletzte Argument kann einen Pointer auf eine Funktion enthalten, die nach erfolgreichem Kompilieren ausgeführt werden soll. Das letzte Argument kann die Argumente dieser Funktion beinhalten.
			
			Da an dieser Stelle erst das eigentliche OpenCL Programm kompiliert wird, muss nun der Output des OpenCL Compilers abgefragt werden.
			
			\newpage			
			\begin{lstlisting}[caption=~Fehlerabfrage OpenCL Compiler]
			if(ret != 0){
				size_t sz; char * bf;

				clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_STATUS, 
					0, NULL, &sz);
				bf = (char*)malloc((sz+1) * sizeof(char));
				if(bf)
				{
					clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_STATUS, 
						sz+1, bf, NULL);
					bf[sz] = 0;
					fprintf(stderr, "\n%s\n", bf);
					free(bf);
				}

				clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_OPTIONS, 
					0, NULL, &sz);
				bf = (char*)malloc((sz+1) * sizeof(char));
				if(bf)
				{
					clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_OPTIONS, 
						sz+1, bf, NULL);
					bf[sz] = 0;
					fprintf(stderr, "\n%s\n", bf);
					free(bf);
				}
				
				clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_LOG, 
					0, NULL, &sz);
				bf = (char*)malloc((sz+1) * sizeof(char));
				if(bf)
				{
					clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_LOG, 
						sz+1, bf, NULL);
					bf[sz] = 0;
					fprintf(stderr, "\n%s\n", bf);
					free(bf);
				} }
			\end{lstlisting}
			
			\newpage
			
			\subsection{Kernel}
			Danach kann das eigentliche \Gls{Kernel} erstellt werden. Dazu muss der Name der Funktion als String übergeben werden. Das Programmieren der Kernels funktioniert ähnlich wie in CUDA.			
			\begin{lstlisting}[caption=~Kerneldefinition]
			__kernel void vecadd(__constant float *x, __constant float* y, __global float *res, const uint size)
			{
  				uint i = get_global_id(0);
  				if(i < size)
    				res[i] = x[i] + y[i];
			}
			\end{lstlisting}
			
			\Glspl{Kernel} müssen mit dem Keyword \li`__kernel` deklariert. Der Rückgabewert ist immer \li`void`. Jedes Objekt liegt per Default im \gls{private Memory} des \Glspl{Workitem}. Arrays müssen also mit dem entsprechenden Keyword deklariert werden, \li`__global` für \gls{global Memory}, \li`__constant` für \gls{constant Memory} und \li`__local` für \gls{local Memory}. Die Unterstriche können weggelassen werden. 
			
			Eine zusätlich definierte Funktion kann vom \Gls{Kernel}, also vom Device aus, wie aus C gewohnt ausgeführt werden. 
			
			Für das \Gls{Kernel} müssen wie gewohnt Buffer erstellt und Speicher kopiert werden. Zudem müssen die Kernelargumente explizit gesetzt werden.
			\begin{lstlisting}[caption=~Kernelaufruf]
			cl_mem d_x  = clCreateBuffer(context, CL_MEM_READ_ONLY, 
				size*sizeof(cl_float), NULL, &ret);
			cl_mem d_y  = clCreateBuffer(context, CL_MEM_READ_ONLY, 
				size*sizeof(cl_float), NULL, &ret);
			cl_mem d_res = clCreateBuffer(context, CL_MEM_WRITE_ONLY, 
				size*sizeof(cl_float), NULL, &ret);
			
			clEnqueueWriteBuffer(command_queue, d_x, CL_TRUE, 0, 
				size*sizeof(cl_float), h_x, 0, NULL, NULL);
			clEnqueueWriteBuffer(command_queue, d_y, CL_TRUE, 0, 
				size*sizeof(cl_float), h_y, 0, NULL, NULL);
			
			cl_kernel kernel_vecadd = clCreateKernel(program, "vecadd", &ret);
			
			
			
			clSetKernelArg(kernel_vecadd, 0, sizeof(cl_mem),  (void *)&d_x);
			clSetKernelArg(kernel_vecadd, 1, sizeof(cl_mem),  (void *)&d_y);
			clSetKernelArg(kernel_vecadd, 2, sizeof(cl_mem),  (void *)&d_res);
			clSetKernelArg(kernel_vecadd, 3, sizeof(cl_uint), &size);
			
			// Ausführen...
			\end{lstlisting}
			
			Ein Buffer kann in verschiedenen Modi erstellt werden (\ref{tab4:flags}).
			\begin{table}[h]
				\centering
				\begin{tabular}{|l|l|}\hline
				\li`CL_MEM_READ_WRITE` & Zum Lesen und zum Schreiben (default) \\
				\li`CL_MEM_WRITE_ONLY` & Das Objekt wird vom \Gls{Kernel} nicht gelesen \\	
				\li`CL_MEM_READ_ONLY`  & Das Objekt wird vom \Gls{Kernel} nicht geschrieben \\
				\li`CL_MEM_USE_HOST_PTR` & Erstellt Speicher im Devicememory aus Hostarray.\\
				                         & ~~Erstellen von verschiedenen Buffern aus dem selben Pointer\\
				                         & ~~ist nicht definiert.\\
				\li`CL_MEM_ALLOC_HOST_PTR` & Wie \li`CL_MEM_USE_HOST_PTR`, aber mit automatischer Allozierung \\
				\li`CL_MEM_COPY_HOST_PTR`  & Wie \li`CL_MEM_USE_HOST_PTR`, aber mit automatischer Kopie\\ \hline
				\end{tabular}
				\caption{Buffermodi}
				\label{tab4:flags}
			\end{table}
			
			Das vorletzte Argument ist eine Referenz auf den Hostspeicher.
			
			Mehrere Flags können grundsätzlich über eine Abtrennung mit | gleichzeitig gesetzt werden. Mit der Angabe von \li`CL_TRUE` wird der Host blockiert. Die Angabe danach gibt einen Offset auf der Speicheradresse an.
							
			\subsection{Command Queues}
			Statt \Glspl{Stream} existieren in OpenCL \Glspl{Command Queue}. Jede Speicheranweisung (Kopieren, Lesen, Allozieren...) muss in eine \Gls{Command Queue} eingereiht werden. Zum Schluss wird die Warteschlange mit dem \Gls{Kernel} ausgeführt und erzeugt dabei ein Event. Das Lesen des Speichers erfolgt, sobald dieses Event stattgefunden hat. Am Ende wird der Speicher freigegeben.
			
		\newpage
		\begin{lstlisting}[caption=~Command Queues und Clean-Up]
		cl_command_queue command_queue = clCreateCommandQueue(context, device_id, 0, &ret);
		
		size_t global_item_size = ... //Zahl der Workitems gesamt
		size_t local_item_size = ... //Größe der Workgroup
		cl_event vecadd_event;
		clEnqueueNDRangeKernel(command_queue, kernel_vecadd, 1, NULL, &global_item_size, &local_item_size, 0, NULL, &vecadd_event);
		
		clEnqueueReadBuffer(command_queue, d_res, CL_TRUE, 0, size*sizeof(cl_float), h_res, 1, &vecadd_event, NULL);  
			
		clFlush(command_queue);
		clFinish(command_queue);
		clReleaseKernel(kernel_vecadd);
		clReleaseProgram(program);
  
		clReleaseMemObject(d_x);
		clReleaseMemObject(d_y);
		clReleaseMemObject(d_res);

		clReleaseCommandQueue(command_queue);
		clReleaseContext(context);

		free(...);
		\end{lstlisting}
		Das letzte Argument von \li`clEnqueueNDRangeKernel`, \li`clEnqueueReadBuffer` und \li`clEnqueueWriteBuffer` enthält eine Referenz auf ein Event. Das Event hat stattgefunden, sobald die Funktion ausgeführt wurde. Das vorletzte Argument enthält eine Liste von Events. Das drittletzte Argument gibt an, auf wie viele dieser Events gewartet werden muss, bis die Funktion ausgeführt werden soll. Jeder \Gls{API} Aufruf erfolgt also grundsätzlich asynchron.
			
		\section{Datentypen und Makros}\label{makros}
		Die OpenCL \Gls{API} definiert sich einige Datentypen um plattformunabhängigkeit zu gewährleisten. Beispielsweise garantiert \li`cl_int`, dass es sich dabei unabhängig von Compiler und Betriebssystem um eine 32bit Ganzzahl handelt.
		
		\textbf{Datentypen:}		
		
		\begin{itemize}
		\item Skalare:\\ \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/scalarDataTypes.html}
		\item Vektor:\\ \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/vectorDataTypes.html}
		\item Abstarkte:\\ \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/abstractDataTypes.html}
		\item Reservierte:\\ \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/reservedDataTypes.html}
		\item Sonstige:\\ \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/otherDataTypes.html}
		\end{itemize}		
		
		Alle Präprozessordirektiven von C99 werden unterstützt. Einige weitere wurden zusätzlich definiert:\\ \url{https://www.khronos.org/registry/OpenCL/sdk/1.1/docs/man/xhtml/preprocessorDirectives.html}		
		
		%\section{Pipes}
		\section{Images}
		Das Image Format ist eine Datenstruktur, die speziell auf Bilformate optimiert wurde.
		\begin{lstlisting}
		cl_mem clCreateImage(
			cl_context context, 
			cl_mem_flags flags,
			const cl_image_format *image_format,
			const cl_image_desc *image_desc,
			void *host_ptr,
			cl_int *errcode_ret)
		\end{lstlisting}		
		Das Erstellen funktionier ähnlich zu einem gewöhnlichen Speicherobjekt. Allerdings handelt es sich dabei um eine Datenstruktur, deren genauer Inhalt angegeben werden muss. \li`image_format` enthält Informationen über das Datenformat des Bildes: \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/cl_image_format.html}
		
		Bei einem CL\_ FLOAT/RGB-Bild besteht jedes Element der Datenstruktur also aus vier float Werten, von denen jede ein Pixel des Bildes beschreibt, also Rotwert, Grünwert, Blauwert und Alphachannel.
		
		\li`cl_image_dsc` enthält Informationen über die Struktur des Bildes, z.B. Höhe und Breite in Pixel: \url{https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/cl_image_desc.html}
		
		\section{Pipes}
		Das Pipe Objekt exisitiert erst seit OpenCl 2.0 und bezeichnet einen globalen Memorybuffer der kontroliert gelesen und geschrieben werden kann. Pipes können vom Host nur zur Übergabe an ein \Gls{Kernel} benutzt werden. Im Device Code können Pipes nur über built-in Funktionen verändert werden: \url{https://www.khronos.org/registry/OpenCL/sdk/2.0/docs/man/xhtml/pipeFunctions.html}
		
		\section{C++ API}
		Es existiert eine C++ Wrapper \Gls{API} \autocite{oclC++API}.  Das Beispiel der Vektoraddition lässt sich somit in C++ umschreiben:
		\begin{lstlisting}[caption=~OpenCL C++ API]
		std::vector<cl::Platform> platformList;
		cl::Platform::get(&platformList);
		cl_context_properties cprops[] = {
			CL_CONTEXT_PLATFORM, (cl_context_properties)(platformList[0])(), 0};
    
		cl::Context context(CL_DEVICE_TYPE_GPU, cprops);

		std::vector<cl::Device> devices = context.getInfo<CL_CONTEXT_DEVICES>();

		cl::Program::Sources sources(1, std::make_pair(source_str, 0));
		cl::Program program(context, sources);
		program.build(devices);

		cl::Buffer d_x = cl::Buffer(
			context, 
			CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, 
			size*sizeof(cl_float), 
			(void*)&h_x[0]);

		cl::Buffer d_y = cl::Buffer(
			context, 
			CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, 
			size*sizeof(cl_float), 
			(void*)&h_y[0]);

		cl::Buffer d_res = cl::Buffer(
			context, 
			CL_MEM_WRITE_ONLY, 
			size*sizeof(cl_float));

		cl::Kernel kernel(program, "vecadd");
		kernel.setArg(0, d_x);
		kernel.setArg(1, d_y);
		kernel.setArg(2, d_res);
		kernel.setArg(3, size);
    
		cl::CommandQueue queue(context, devices[0], 0);

		queue.enqueueNDRangeKernel(
			kernel, 
			cl::NullRange, 
			cl::NDRange(size), 
			cl::NullRange);
 
		cl_float *h_res = (cl_float*)queue.enqueueMapBuffer(
			d_res,
			CL_TRUE,
			CL_MAP_READ,
			0,
			size*sizeof(cl_float));

		//Ausgabe auf Host

		queue.enqueueUnmapMemObject(d_res, (void*)h_res);
		\end{lstlisting}
		Die OpenCL Objekte sind nun Instanzen echter C++ Klassen, die sich im Namespace \li`cl` befinden. Das \li`cl_mem` Objekt nennt sich nun \li`Buffer` und wird durch einen expliziten Aufruf eines Konstruktors erstellt. Funktionen, die auf Objekten operieren, sind nun Member-Funktionen der entsprechenden Klasse. Am Ende eines Scopes wird ihr Destruktor automatisch aufgerufen, ein explizites freigeben von Speicher ist daher nicht nötig (außer Ausgabearray auf Host).
		
		
		\section{OpenCL C++}\label{OCLC++}
		Die OpenCL C++ \Gls{Kernel} Language ist seit Version 2.2 verfügbar und enthält eine Untermenge des C++14 Standards, z.B. Lambda Expressions, Templates oder Klassen. Außerdem existiert eine optimierte Implementierung der Standard Template Library, die sich an C++11 orientiert. 
		
		Folgende Features wurden bisher noch nicht implementiert:
		\begin{itemize}
			\item Exceptions
			\item Allocate/Release Memory
			\item Virtual Functions 
			\item Abstract Classes Function Pointers
			\item Recursion 
			\item goto
		\end{itemize}
		
		Für OpenCL C++ wurde eine eigene Spezifikation angefertigt. \autocite{oclC++Spec}
		
		Folgendes Beispiel zeigt eine gewöhnliche Template-Klasse für Matrizen in C++:
		\begin{lstlisting}[caption=~Matrix OpenCl C++]
		template<typename T, size_t Rows, size_t Columns>
		class matrix 
		{
			public:
			matrix(){}
			T& operator()(size_t row, size_t col) {return _data[row-1][col-1];}

			constexpr size_t num_rows(){return Rows;}
			constexpr size_t num_columns(){return Columns;}
			
			private:
			T _data[Rows][Columns];
		};
		\end{lstlisting}
		
		Die Addition zweier Matrizen lässt sich durch Überladen des $+$-Operators implementieren:
		\begin{lstlisting}[caption=~Matrixaddition OpenCl C++]
		template<typename T, size_t Rows, size_t Columns> 
		matrix<T, Rows, Columns>operator+(
		const matrix<T, Rows, Columns>& x, const matrix<T, Rows, Columns>& y) 
		{
			matrix<T, Rows, Columns> tmp;
			
			for(size_t row = 0; row < Rows; ++row ) 
			{
				for(size_t column = 0; column < Columns; ++column) 
				{
					tmp(row, column) = x(row, column) + y(row, column);
				}
			}
			
			return tmp;
		}
		\end{lstlisting}
		
		Dieser C++ Code lässt sich dank OpenCl C++ exakt so im Devicecode implementieren. In einem \Gls{Kernel} kann dann dieser Code verwendet werden, um auf dem Device eine Matrixaddition auszuführen. Im folgenden Beispiel werden Matrizen addiert, indem jeweils ein \li`float4` zu einer $2\times 2$ Matrix umgewandelt, addiert und danach zurückkonvertiert wird:	
		\begin{lstlisting}[caption=~OpenCl C++ Kernel]
		matrix<float, 2, 2> float4_to_matrix(float4 *in) 
		{
			matrix<float, 2, 2> m;
			float4 tmp = *in;
			m(1,1) = tmp.s0;
			m(1,2) = tmp.s1;
			m(2,1) = tmp.s2;
			m(2,2) = tmp.s3;
			
			return m;
		}
		float4 matrix_to_float4(const matrix<float, 2, 2>& m)
		{
			float4 vec;
			vec.s0 = m(1,1) ;
			vec.s1 = m(1,2) ;
			vec.s2 = m(2,1) ;
			vec.s3 = m(2,2) ;

			return vec;
		}





		__kernel void add_matrices(float4 *in1, float4 *in2, float4 *result) 
		{
			size_t idx = get_global_id(0);
			matrix<float, 2, 2> m1 = float4_to_matrix(in1[idx]);
			matrix<float, 2, 2> m2 = float4_to_matrix(in2[idx]);
			result[idx] = matrix_to_float4(m1 + m2);
		}
		\end{lstlisting}
		
		Abgesehen vom \Gls{Kernel} selbst unterscheidet sich dieser Code nicht von gewöhnlichem C++.
